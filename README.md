# ENCM 509-Fundamentals of Biometric Systems Design Winter 2024 Labs
By: Abhay Khosla and Parbir Lehal

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) 	![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)

**Lab 1:** Introduction to Python, Jupyter Notebooks and Markdown

**Lab 2:** In this lab, we explored the process of identity recognition in biometrics, focusing on the identification and verification of specific words such as "Labs" and "Four" through signature data acquisition. We conducted an analysis on a collection of genuine and forged word samples, enhancing our understanding of the underlying statistical methodologies for distinguishing between genuine users and impostors.

**Lab 3:** In this lab, we delve into biometric-based verification techniques, utilizing a dataset from Lab 2 composed of 30 genuine and 30 forged instances of the word "labs." We apply the Gaussian Mixture Model, a statistical tool introduced in our lectures, to classify and analyze these samples, focusing on metrics like False Acceptance Rate (FAR) and False Rejection Rate (FRR) to assess the model's accuracy and effectiveness in distinguishing between genuine and forged signatures.

**Lab 4:** In this lab, we venture into the realm of image processing, specifically focusing on fingerprint recognition by analyzing features extracted from fingerprint images in .bmp format. This exploration is pivotal for understanding biometric security systems widely used across various devices like mobile phones and laptops. Our primary objective is to grasp the fingerprint recognition process through hands-on implementation of feature extraction and matching algorithms, using the DigitalPersona USB fingerprint reader for image capture. Additionally, this lab enhances our practical skills in integrating theoretical concepts with Python programming, notably through the manual setup of the OpenCV library, laying the groundwork for proficiency in biometric system design and feature extraction analysis.

**Lab 5:** In Part II of our lab series on fingerprint image processing and matching, we delve deeper into fingerprint verification techniques, utilizing data collected with the DigitalPersona USB device. This session focuses on enhancing our understanding of fingerprint analysis through the application of Gabor filtering to detect ridge patterns, adjusting its angle and frequency parameters for optimal results. Additionally, we explore the intricacies of minutiae-based fingerprint matching, navigating through its complexities to refine our biometric matching capabilities. By comparing fingerprints from identical prints under different impressions and distinct prints, we aim to solidify our understanding of biometric matching, setting appropriate thresholds for scoring to accurately classify outcomes as false negatives, true positives, false positives, and true negatives. 

**Lab 6:** In this lab, we explore the domain of biometric authentication through face recognition technology, a method for identifying and verifying individuals by detecting facial features and employing image processing techniques for feature enhancement and extraction. Our focus is to comprehend the face recognition process using Principal Component Analysis (PCA) for feature extraction and the K-Nearest Neighbours (KNN) algorithm for classification based on similarity scoring. Utilizing various Python libraries, we aim to perform these tasks and thoroughly evaluate the outcomes in our lab report, thereby gaining a deeper understanding of face recognition techniques and their application in biometric authentication systems.

**Lab 7:** In this lab, we delve into the analysis of motion data captured by the Leap Motion sensor, a device designed for motion recognition, particularly hand movements and gestures within its vicinity. Utilizing infrared light for motion detection, this sensor provides a fascinating glimpse into human-computer interaction. Our investigation employs machine learning principles to accurately recognize specific hand gestures, notably the formation of a circle and a hand swipe, by analyzing movement coordinates and hand joint positions. We focus on leveraging the deep learning capabilities of Long Short Term Memory (LSTM) networks, ideal for classifying sequential data such as the time series data generated by hand movements. Throughout the lab, we experiment with various LSTM model parameters to enhance model accuracy and overall performance. By comparing different LSTM configurations, we aim to identify the most effective model setup for hand gesture classification.

**Lab 8:** In our exploration of Bayesian Networks within this lab report, we delve into a framework renowned for its understanding and managing uncertainties through probabilistic reasoning. By theoretical concepts with hands-on examples, we aim to illuminate the significance of Bayesian Networks in the realm of machine reasoning. Utilizing PyAgrum, a Python library dedicated to probabilistic and graphical models, we will craft and manipulate Bayesian Networks, gaining insights into the interplay among various variables. Through the application of Bayes' rule and the chain rule, we will compute joint probabilities, enhancing our comprehension of probabilistic dependencies and inferences. By manually solving exercises alongside our computational approach, we aim to cross-verify our findings, thereby reinforcing our understanding. This lab serves as a solid foundation in probabilistic modeling.